{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd42ab45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ef60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3227518\n",
      "Total Characters 3227518\n",
      "The Project Gutenberg eBook of War and Peace, by Leo Tolstoy\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org. If you are not located in the United States, you\n",
      "will have to check the laws of the country where you are located before\n",
      "using this eBook.\n",
      "\n",
      "Title: War and Peace\n",
      "\n",
      "Author: Leo Tolstoy\n",
      "\n",
      "Translators: Louise and Aylmer Maude\n",
      "\n",
      "Release Date: April, 2001 [eBook #2600]\n",
      "[Most recently updated: June 14, 2022]\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "Produced by: An Anonymous Volunteer and David Widger\n",
      "\n",
      "*** START OF THE PROJECT GUTENBERG EBOOK WAR AND PEACE ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WAR AND PEACE\n",
      "\n",
      "\n",
      "By Leo Tolstoy/Tolstoi\n",
      "\n",
      "\n",
      "    Contents\n",
      "\n",
      "    BOOK ONE: 1805\n",
      "\n",
      "    CHAPTER I\n",
      "\n",
      "    CHAPTER II\n",
      "\n",
      "    CHAPTER III\n",
      "\n",
      "    CHAPTER IV\n",
      "\n",
      "    CHAPTER V\n",
      "\n",
      "    CHAPTER \n",
      "\n",
      " !\"#$%'()*,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyzÀÁÉàáâäæçèéêëíîïóôöúüýœ—‘’“”\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "with open(\"../war_and_peace.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(len(text))\n",
    "\n",
    "print(\"Total Characters\", len(text))\n",
    "\n",
    "print(text[:1000])\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c43f89cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/anthonylewallen/Programming/ai_engineering/generatively_pretrained_transformer/src\n",
      "Exists: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Exists:\", os.path.exists(\"generatively_pretrained_transformer/war_and_peace.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70269b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/anthonylewallen/Programming/ai_engineering/generatively_pretrained_transformer/src\n",
      "Python: /opt/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Python:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00bdb0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 61, 71, 1, 48, 71, 68, 75, 76, 71, 65]\n",
      "Leo Tolstoi\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i, ch in enumerate(chars) }\n",
    "int_to_string = {i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "print(encode(\"Leo Tolstoi\"))\n",
    "print(decode(encode(\"Leo Tolstoi\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b952496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3227518]) torch.int64\n",
      "tensor([48, 64, 61,  1, 44, 74, 71, 66, 61, 59, 76,  1, 35, 77, 76, 61, 70, 58,\n",
      "        61, 74, 63,  1, 61, 30, 71, 71, 67,  1, 71, 62,  1, 51, 57, 74,  1, 57,\n",
      "        70, 60,  1, 44, 61, 57, 59, 61, 11,  1, 58, 81,  1, 40, 61, 71,  1, 48,\n",
      "        71, 68, 75, 76, 71, 81,  0,  0, 48, 64, 65, 75,  1, 61, 30, 71, 71, 67,\n",
      "         1, 65, 75,  1, 62, 71, 74,  1, 76, 64, 61,  1, 77, 75, 61,  1, 71, 62,\n",
      "         1, 57, 70, 81, 71, 70, 61,  1, 57, 70, 81, 79, 64, 61, 74, 61,  1, 65,\n",
      "        70,  1, 76, 64, 61,  1, 49, 70, 65, 76, 61, 60,  1, 47, 76, 57, 76, 61,\n",
      "        75,  1, 57, 70, 60,  0, 69, 71, 75, 76,  1, 71, 76, 64, 61, 74,  1, 72,\n",
      "        57, 74, 76, 75,  1, 71, 62,  1, 76, 64, 61,  1, 79, 71, 74, 68, 60,  1,\n",
      "        57, 76,  1, 70, 71,  1, 59, 71, 75, 76,  1, 57, 70, 60,  1, 79, 65, 76,\n",
      "        64,  1, 57, 68, 69, 71, 75, 76,  1, 70, 71,  1, 74, 61, 75, 76, 74, 65,\n",
      "        59, 76, 65, 71, 70, 75,  0, 79, 64, 57, 76, 75, 71, 61, 78, 61, 74, 13,\n",
      "         1, 53, 71, 77,  1, 69, 57, 81,  1, 59, 71, 72, 81,  1, 65, 76, 11,  1,\n",
      "        63, 65, 78, 61,  1, 65, 76,  1, 57, 79, 57, 81,  1, 71, 74,  1, 74, 61,\n",
      "        12, 77, 75, 61,  1, 65, 76,  1, 77, 70, 60, 61, 74,  1, 76, 64, 61,  1,\n",
      "        76, 61, 74, 69, 75,  0, 71, 62,  1, 76, 64, 61,  1, 44, 74, 71, 66, 61,\n",
      "        59, 76,  1, 35, 77, 76, 61, 70, 58, 61, 74, 63,  1, 40, 65, 59, 61, 70,\n",
      "        75, 61,  1, 65, 70, 59, 68, 77, 60, 61, 60,  1, 79, 65, 76, 64,  1, 76,\n",
      "        64, 65, 75,  1, 61, 30, 71, 71, 67,  1, 71, 74,  1, 71, 70, 68, 65, 70,\n",
      "        61,  1, 57, 76,  0, 79, 79, 79, 13, 63, 77, 76, 61, 70, 58, 61, 74, 63,\n",
      "        13, 71, 74, 63, 13,  1, 37, 62,  1, 81, 71, 77,  1, 57, 74, 61,  1, 70,\n",
      "        71, 76,  1, 68, 71, 59, 57, 76, 61, 60,  1, 65, 70,  1, 76, 64, 61,  1,\n",
      "        49, 70, 65, 76, 61, 60,  1, 47, 76, 57, 76, 61, 75, 11,  1, 81, 71, 77,\n",
      "         0, 79, 65, 68, 68,  1, 64, 57, 78, 61,  1, 76, 71,  1, 59, 64, 61, 59,\n",
      "        67,  1, 76, 64, 61,  1, 68, 57, 79, 75,  1, 71, 62,  1, 76, 64, 61,  1,\n",
      "        59, 71, 77, 70, 76, 74, 81,  1, 79, 64, 61, 74, 61,  1, 81, 71, 77,  1,\n",
      "        57, 74, 61,  1, 68, 71, 59, 57, 76, 61, 60,  1, 58, 61, 62, 71, 74, 61,\n",
      "         0, 77, 75, 65, 70, 63,  1, 76, 64, 65, 75,  1, 61, 30, 71, 71, 67, 13,\n",
      "         0,  0, 48, 65, 76, 68, 61, 25,  1, 51, 57, 74,  1, 57, 70, 60,  1, 44,\n",
      "        61, 57, 59, 61,  0,  0, 29, 77, 76, 64, 71, 74, 25,  1, 40, 61, 71,  1,\n",
      "        48, 71, 68, 75, 76, 71, 81,  0,  0, 48, 74, 57, 70, 75, 68, 57, 76, 71,\n",
      "        74, 75, 25,  1, 40, 71, 77, 65, 75, 61,  1, 57, 70, 60,  1, 29, 81, 68,\n",
      "        69, 61, 74,  1, 41, 57, 77, 60, 61,  0,  0, 46, 61, 68, 61, 57, 75, 61,\n",
      "         1, 32, 57, 76, 61, 25,  1, 29, 72, 74, 65, 68, 11,  1, 17, 15, 15, 16,\n",
      "         1, 55, 61, 30, 71, 71, 67,  1,  4, 17, 21, 15, 15, 56,  0, 55, 41, 71,\n",
      "        75, 76,  1, 74, 61, 59, 61, 70, 76, 68, 81,  1, 77, 72, 60, 57, 76, 61,\n",
      "        60, 25,  1, 38, 77, 70, 61,  1, 16, 19, 11,  1, 17, 15, 17, 17, 56,  0,\n",
      "         0, 40, 57, 70, 63, 77, 57, 63, 61, 25,  1, 33, 70, 63, 68, 65, 75, 64,\n",
      "         0,  0, 31, 64, 57, 74, 57, 59, 76, 61, 74,  1, 75, 61, 76,  1, 61, 70,\n",
      "        59, 71, 60, 65, 70, 63, 25,  1, 49, 48, 34, 12, 23,  0,  0, 44, 74, 71,\n",
      "        60, 77, 59, 61, 60,  1, 58, 81, 25,  1, 29, 70,  1, 29, 70, 71, 70, 81,\n",
      "        69, 71, 77, 75,  1, 50, 71, 68, 77, 70, 76, 61, 61, 74,  1, 57, 70, 60,\n",
      "         1, 32, 57, 78, 65, 60,  1, 51, 65, 60, 63, 61, 74,  0,  0, 10, 10, 10,\n",
      "         1, 47, 48, 29, 46, 48,  1, 43, 34,  1, 48, 36, 33,  1, 44, 46, 43, 38,\n",
      "        33, 31, 48,  1, 35, 49, 48, 33, 42, 30, 33, 46, 35,  1, 33, 30, 43, 43,\n",
      "        39,  1, 51, 29, 46,  1, 29, 42, 32,  1, 44, 33, 29, 31, 33,  1, 10, 10,\n",
      "        10,  0,  0,  0,  0,  0, 51, 29, 46,  1, 29, 42, 32,  1, 44, 33, 29, 31,\n",
      "        33,  0,  0,  0, 30, 81,  1, 40, 61, 71,  1, 48, 71, 68, 75, 76, 71, 81,\n",
      "        14, 48, 71, 68, 75, 76, 71, 65,  0,  0,  0,  1,  1,  1,  1, 31, 71, 70,\n",
      "        76, 61, 70, 76, 75,  0,  0,  1,  1,  1,  1, 30, 43, 43, 39,  1, 43, 42,\n",
      "        33, 25,  1, 16, 23, 15, 20,  0,  0,  1,  1,  1,  1, 31, 36, 29, 44, 48,\n",
      "        33, 46,  1, 37,  0,  0,  1,  1,  1,  1, 31, 36, 29, 44, 48, 33, 46,  1,\n",
      "        37, 37,  0,  0,  1,  1,  1,  1, 31, 36, 29, 44, 48, 33, 46,  1, 37, 37,\n",
      "        37,  0,  0,  1,  1,  1,  1, 31, 36, 29, 44, 48, 33, 46,  1, 37, 50,  0,\n",
      "         0,  1,  1,  1,  1, 31, 36, 29, 44, 48, 33, 46,  1, 50,  0,  0,  1,  1,\n",
      "         1,  1, 31, 36, 29, 44, 48, 33, 46,  1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4039f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7a26057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48, 64, 61,  1, 44, 74, 71, 66, 61])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1adb52dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [48] the target: 64\n",
      "when input is [48, 64] the target: 61\n",
      "when input is [48, 64, 61] the target: 1\n",
      "when input is [48, 64, 61, 1] the target: 44\n",
      "when input is [48, 64, 61, 1, 44] the target: 74\n",
      "when input is [48, 64, 61, 1, 44, 74] the target: 71\n",
      "when input is [48, 64, 61, 1, 44, 74, 71] the target: 66\n",
      "when input is [48, 64, 61, 1, 44, 74, 71, 66] the target: 61\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context.tolist()} the target: {target.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37bdb5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 76,  65,  78,  61,   1,  72,  74,  71],\n",
      "        [ 57,  76,   1,  76,  64,  61,  74,  61],\n",
      "        [ 62,  76,  61,  74,   1,  79,  65,  75],\n",
      "        [  1,  70,  65,  59,  61,  74,  11, 110]])\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 65,  78,  61,   1,  72,  74,  71,  72],\n",
      "        [ 76,   1,  76,  64,  61,  74,  61,  11],\n",
      "        [ 76,  61,  74,   1,  79,  65,  75,  60],\n",
      "        [ 70,  65,  59,  61,  74,  11, 110,   1]])\n",
      "----\n",
      "When input is [76] the target: 65\n",
      "When input is [76, 65] the target: 78\n",
      "When input is [76, 65, 78] the target: 61\n",
      "When input is [76, 65, 78, 61] the target: 1\n",
      "When input is [76, 65, 78, 61, 1] the target: 72\n",
      "When input is [76, 65, 78, 61, 1, 72] the target: 74\n",
      "When input is [76, 65, 78, 61, 1, 72, 74] the target: 71\n",
      "When input is [76, 65, 78, 61, 1, 72, 74, 71] the target: 72\n",
      "When input is [57] the target: 76\n",
      "When input is [57, 76] the target: 1\n",
      "When input is [57, 76, 1] the target: 76\n",
      "When input is [57, 76, 1, 76] the target: 64\n",
      "When input is [57, 76, 1, 76, 64] the target: 61\n",
      "When input is [57, 76, 1, 76, 64, 61] the target: 74\n",
      "When input is [57, 76, 1, 76, 64, 61, 74] the target: 61\n",
      "When input is [57, 76, 1, 76, 64, 61, 74, 61] the target: 11\n",
      "When input is [62] the target: 76\n",
      "When input is [62, 76] the target: 61\n",
      "When input is [62, 76, 61] the target: 74\n",
      "When input is [62, 76, 61, 74] the target: 1\n",
      "When input is [62, 76, 61, 74, 1] the target: 79\n",
      "When input is [62, 76, 61, 74, 1, 79] the target: 65\n",
      "When input is [62, 76, 61, 74, 1, 79, 65] the target: 75\n",
      "When input is [62, 76, 61, 74, 1, 79, 65, 75] the target: 60\n",
      "When input is [1] the target: 70\n",
      "When input is [1, 70] the target: 65\n",
      "When input is [1, 70, 65] the target: 59\n",
      "When input is [1, 70, 65, 59] the target: 61\n",
      "When input is [1, 70, 65, 59, 61] the target: 74\n",
      "When input is [1, 70, 65, 59, 61, 74] the target: 11\n",
      "When input is [1, 70, 65, 59, 61, 74, 11] the target: 110\n",
      "When input is [1, 70, 65, 59, 61, 74, 11, 110] the target: 1\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1369)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    \n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3140fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 76,  65,  78,  61,   1,  72,  74,  71],\n",
      "        [ 57,  76,   1,  76,  64,  61,  74,  61],\n",
      "        [ 62,  76,  61,  74,   1,  79,  65,  75],\n",
      "        [  1,  70,  65,  59,  61,  74,  11, 110]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbee1a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 111])\n",
      "tensor(5.3340, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Á-Yéqèêx1;O68-EèäägäAE2eu,zKOgwe .l04E*HbIr. ëR,j‘î%uu0Zô33ôo[gGczYXLR-Y=nï8îlaaäBSRCoÁq'LcOHa\"I .Vq\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1369)\n",
    "\n",
    "class MyLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        \n",
    "        logits = self.token_embedding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:    \n",
    "            B, T, C = logits.shape \n",
    "            logits = logits.view(B*T, C) # Explicitly detail to a 2D B, C, T shape for cross_entropy\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss  # loss is 5.3340, initial guestimate is a bit off\n",
    "    \n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # the idx is a (B, T) array of indices i the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Predictions\n",
    "            logits, loss = self(idx)\n",
    "            # Last time step\n",
    "            logits = logits[:, -1, :]\n",
    "            # Softmax\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # Get a Sample\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            # Append the sample to the sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "            \n",
    "        return idx\n",
    "            \n",
    "    \n",
    "\n",
    "m = MyLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "# zero is new line character\n",
    " \n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "956898e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pytorch optimization object\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50efafbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3886566162109375\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100000):\n",
    "    \n",
    "    # sample data for training\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate loss\n",
    "    # We notice that the loss eventually minimizes at approx 2.25 - 2.49\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“We bothf\n",
      "\n",
      "mpof uprerust tllowhilyan m teleld ollkn.\n",
      "fe\n",
      "verng he wad. ame stheve The se wim Pin hore o ayo in y, nthtemaew\n",
      "v ssorn! wineoulin t.\n",
      "outhengarepe s, t; unthersthepenon cavaneenowhectid XXXI?... antinowin wll’sca hialit cee mayoas. aue am a w’sa augherenoldesef pa hitheat aze fon’l herevanasof alangroly ana pis as a arag?” Whelly p sangl waistomeee toiserríl t wimpppous ftal ored ede’?”\n",
      "“cke ato bly\n",
      "wo\n",
      "mprminomevewad ete ng tsas jowisewer burínd, someng ay anaca gha og cieace ryovong\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sentences with some formed words but mostly gibberish are printed.\n",
    "# Basically the tokens are not cohesive or talking to each other.\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c062d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4b1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296c538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
